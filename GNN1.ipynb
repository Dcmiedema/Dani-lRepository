{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2d9b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "if torch.__version__ != '1.6.0':\n",
    "  !pip uninstall torch -y\n",
    "  !pip uninstall torchvision -y\n",
    "  !pip install torch==1.6.0\n",
    "  !pip install torchvision==0.7.0\n",
    "\n",
    "# Check pytorch version and make sure you use a GPU Kernel\n",
    "!python -c \"import torch; print(torch.__version__)\"\n",
    "!python -c \"import torch; print(torch.version.cuda)\"\n",
    "!python --version\n",
    "!nvidia-smi\n",
    "import torch\n",
    "pytorch_version = f\"torch-{torch.__version__}.html\"\n",
    "!pip install --no-index torch-scatter -f https://pytorch-geometric.com/whl/$pytorch_version\n",
    "!pip install --no-index torch-sparse -f https://pytorch-geometric.com/whl/$pytorch_version\n",
    "!pip install --no-index torch-cluster -f https://pytorch-geometric.com/whl/$pytorch_version\n",
    "!pip install --no-index torch-spline-conv -f https://pytorch-geometric.com/whl/$pytorch_version\n",
    "!pip install torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c05e79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install rdkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e97b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "import numpy as np\n",
    "import rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit import rdBase\n",
    "from rdkit.Chem.rdchem import HybridizationType\n",
    "from rdkit import RDConfig\n",
    "from rdkit.Chem import ChemicalFeatures\n",
    "from rdkit.Chem.rdchem import BondType as BT\n",
    "import torch.nn.functional as F\n",
    "from torch_sparse import coalesce\n",
    "import pandas as pd\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import (InMemoryDataset, download_url, extract_zip,\n",
    "                                  Data)\n",
    "import os\n",
    "import os.path as osp\n",
    "from torch_geometric.data import Dataset\n",
    "from torch_sparse import coalesce\n",
    "import torch.utils.data \n",
    "from torch.utils.data.dataloader import default_collate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fd7b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN1(InMemoryDataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None,\n",
    "                 pre_filter=None):\n",
    "        super(GNN1, self).__init__(root, transform, pre_transform, pre_filter)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property \n",
    "    def raw_file_names(self):\n",
    "        return 'raw.pt' if rdkit is None else 'raw.csv'\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return 'data.pt'\n",
    "\n",
    "    def download(self):\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "        data = pd.read_csv('JSONdata (1).csv')\n",
    "        data_smiles = data['smiles']\n",
    "        data_list = []\n",
    "       \n",
    "        writer = Chem.SDWriter('temporary.sdf')\n",
    "        for m in data_smiles.values:\n",
    "            mol = Chem.rdmolfiles.MolFromSmiles(m)\n",
    "            # mol = Chem.rdmolops.AddHs(mol)   # explicit trivial Hs (excluded)\n",
    "            writer.write(mol)\n",
    "        del writer\n",
    "\n",
    "        suppl = Chem.SDMolSupplier('temporary.sdf', removeHs=False)\n",
    "        target = torch.tensor(data['energy'].values, dtype=torch.float)\n",
    "\n",
    "        atoms = []\n",
    "        bonds = []\n",
    "        dict_types = dict()\n",
    "        dict_bonds = dict()\n",
    "        for i in data_smiles:\n",
    "            mol= Chem.MolFromSmiles(i)\n",
    "            for x,j in zip(mol.GetAtoms(),mol.GetBonds()):\n",
    "                if x.GetSymbol() not in atoms:\n",
    "                    atoms.append(x.GetSymbol())\n",
    "                if j.GetBondType() not in bonds:\n",
    "                    bonds.append(j.GetBondType())\n",
    "        for i in range(len(atoms)):\n",
    "            dict_types[atoms[i]] = i\n",
    "        for i in range(len(bonds)):\n",
    "            dict_bonds[bonds[i]] = i\n",
    "        dict_types['H'] = len(dict_types)\n",
    "\n",
    "        for mol in suppl:\n",
    "            N = mol.GetNumAtoms()\n",
    "            text = suppl.GetItemText(i)\n",
    "            pos = text.split('\\n')[4:4 + N]\n",
    "            pos = [[float(x) for x in line.split()[:3]] for line in pos]\n",
    "            pos = torch.tensor(pos, dtype=torch.float)\n",
    "            type_idx = []\n",
    "            aromatic = []\n",
    "            ring = []\n",
    "            sp = []\n",
    "            sp2 = []\n",
    "            sp3 = []\n",
    "            sp3d = []\n",
    "            sp3d2 = []\n",
    "            num_hs = []\n",
    "            num_neighbors = []\n",
    "            for atom in mol.GetAtoms():\n",
    "                type_idx.append(dict_types[atom.GetSymbol()])\n",
    "                aromatic.append(1 if atom.GetIsAromatic() else 0)\n",
    "                ring.append(1 if atom.IsInRing() else 0)\n",
    "                hybridization = atom.GetHybridization()\n",
    "                sp.append(1 if hybridization == HybridizationType.SP else 0)\n",
    "                sp2.append(1 if hybridization == HybridizationType.SP2 else 0)\n",
    "                sp3.append(1 if hybridization == HybridizationType.SP3 else 0)\n",
    "                sp3d.append(1 if hybridization == HybridizationType.SP3D else 0)\n",
    "                sp3d2.append(1 if hybridization == HybridizationType.SP3D2 else 0)\n",
    "                num_hs.append(atom.GetTotalNumHs(includeNeighbors=True))\n",
    "                num_neighbors.append(len(atom.GetNeighbors()))\n",
    "            x1 = F.one_hot(torch.tensor(type_idx), num_classes=len(dict_types))\n",
    "            x2 = torch.tensor([aromatic, ring, sp, sp2, sp3, sp3d, sp3d2], dtype=torch.float).t().contiguous()\n",
    "            x3 = F.one_hot(torch.tensor(num_neighbors) , num_classes=7)\n",
    "            x4 = F.one_hot(torch.tensor(num_hs), num_classes=5)\n",
    "            x = torch.cat([x1.to(torch.float), x2, x3.to(torch.float),x4.to(torch.float)], dim=-1)\n",
    "         \n",
    "            row, col, bond_idx, conj, ring, stereo = [], [], [], [], [], []\n",
    "            for bond in mol.GetBonds():\n",
    "                start, end = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
    "                row += [start, end]\n",
    "                col += [end, start]\n",
    "                bond_idx += 2 * [dict_bonds[bond.GetBondType()]]\n",
    "                conj.append(bond.GetIsConjugated())\n",
    "                conj.append(bond.GetIsConjugated())\n",
    "                ring.append(bond.IsInRing())\n",
    "                ring.append(bond.IsInRing())\n",
    "                stereo.append(bond.GetStereo())\n",
    "                stereo.append(bond.GetStereo())\n",
    "            edge_index = torch.tensor([row, col], dtype=torch.long)\n",
    "            e1 = F.one_hot(torch.tensor(bond_idx).to(torch.long),num_classes=len(dict_bonds)).to(torch.float)\n",
    "            e2 = torch.tensor([conj, ring], dtype=torch.float).t().contiguous()\n",
    "            e3 = F.one_hot(torch.tensor(stereo).to(torch.long),num_classes=6).to(torch.float)\n",
    "            edge_attr = torch.cat([e1, e2, e3], dim=-1)\n",
    "            edge_index, edge_attr = coalesce(edge_index, edge_attr, N, N)\n",
    "\n",
    "            y = target[i].unsqueeze(0)\n",
    "          \n",
    "            data = Data(x=x, pos=pos, edge_index=edge_index,\n",
    "                     edge_attr=edge_attr,  y = y)\n",
    "         \n",
    "            data_list.append(data)\n",
    "\n",
    "        torch.save((self.collate(data_list)), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430d5a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = GNN1('data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc90fc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F \n",
    "from torch_geometric.nn import GCNConv, TopKPooling, global_mean_pool\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70592df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 64\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        # Init parent\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(42)\n",
    "\n",
    "        # GCN layers\n",
    "        self.initial_conv = GCNConv(dataset.num_features, embedding_size)\n",
    "        self.conv1 = GCNConv(embedding_size, embedding_size)\n",
    "        self.conv2 = GCNConv(embedding_size, embedding_size)\n",
    "        self.conv3 = GCNConv(embedding_size, embedding_size)\n",
    "\n",
    "        # Output layer\n",
    "        self.out = Linear(embedding_size*2, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, batch_index):\n",
    "        # First Conv layer\n",
    "        hidden = self.initial_conv(x, edge_index)\n",
    "        hidden = F.tanh(hidden)\n",
    "\n",
    "        # Other Conv layers\n",
    "        hidden = self.conv1(hidden, edge_index)\n",
    "        hidden = F.tanh(hidden)\n",
    "        hidden = self.conv2(hidden, edge_index)\n",
    "        hidden = F.tanh(hidden)\n",
    "        hidden = self.conv3(hidden, edge_index)\n",
    "        hidden = F.tanh(hidden)\n",
    "          \n",
    "        # Global Pooling (stack different aggregations)\n",
    "        hidden = torch.cat([gmp(hidden, batch_index), \n",
    "                            gap(hidden, batch_index)], dim=1)\n",
    "\n",
    "        # Apply a final (linear) classifier.\n",
    "        out = self.out(hidden)\n",
    "\n",
    "        return out, hidden\n",
    "\n",
    "model = GCN()\n",
    "print(model)\n",
    "print(\"Number of parameters: \", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1322ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import DataLoader\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Root mean squared error\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0007)  \n",
    "\n",
    "# Use GPU for training\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Wrap data in a data loader\n",
    "data_size = len(dataset)\n",
    "NUM_GRAPHS_PER_BATCH = 64\n",
    "loader = DataLoader(dataset[:int(data_size * 0.8)], \n",
    "                    batch_size=NUM_GRAPHS_PER_BATCH, shuffle=True)\n",
    "test_loader = DataLoader(dataset[int(data_size * 0.8):], \n",
    "                         batch_size=NUM_GRAPHS_PER_BATCH, shuffle=True)\n",
    "\n",
    "def train(data):\n",
    "    # Enumerate over the data\n",
    "    for batch in loader:\n",
    "        # Use GPU\n",
    "        batch.to(device)  \n",
    "        # Reset gradients\n",
    "        optimizer.zero_grad() \n",
    "        # Passing the node features and the connection info\n",
    "        pred, embedding = model(batch.x.float(), batch.edge_index, batch.batch) \n",
    "        # Calculating the loss and gradients\n",
    "        loss = loss_fn(pred, batch.y)     \n",
    "        loss.backward()  \n",
    "        # Update using the gradients\n",
    "        optimizer.step()   \n",
    "    return loss, embedding\n",
    "\n",
    "print(\"Starting training...\")\n",
    "losses = []\n",
    "for epoch in range(2000):\n",
    "    loss, h = train(dataset)\n",
    "    losses.append(loss)\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch} | Train Loss {loss}\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0032d87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "losses_float = [float(loss.cpu().detach().numpy()) for loss in losses] \n",
    "loss_indices = [i for i,l in enumerate(losses_float)] \n",
    "plt = sns.lineplot(loss_indices, losses_float)\n",
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4921e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the results for one batch\n",
    "test_batch = next(iter(test_loader))\n",
    "with torch.no_grad():\n",
    "    test_batch.to(device)\n",
    "    pred, embed = model(test_batch.x.float(), test_batch.edge_index, test_batch.batch) \n",
    "    df = pd.DataFrame()\n",
    "    df[\"y_real\"] = test_batch.y.tolist()\n",
    "    df[\"y_pred\"] = pred.tolist()\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
